{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a7da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_parquet('../data/cleaned_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9745a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['margin_rate'] = (df['seller_price'] - df['seller_earning']) / df['seller_price']\n",
    "df.drop(columns=['product_color', 'product_id'], inplace=True)\n",
    "df.drop(columns=['product_category_encoded','has_cross_border_fees_encoded'], inplace=True)\n",
    "\n",
    "df1 = df\n",
    "# Create Derived Features\n",
    "df1['price_to_earning_ratio'] = df1['price_usd'] / (df1['seller_earning'] + 1)  # Avoid division by zero\n",
    "df1['price_per_like'] = df1['price_usd'] / (df1['product_like_count'] + 1)      # Avoid division by zero\n",
    "df1['seller_activity_ratio'] = df1['seller_products_sold'] / (df1['seller_num_products_listed'] + 1)  # Avoid division by zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39c4f670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Validation ROC-AUC: 0.8566 | Time: 0.01 min\n",
      "XGBoost Learning Curve completed in 0.09 min\n",
      "XGBoost Learning Curve completed in 0.09 min\n",
      "[LightGBM] [Info] Number of positive: 2471, number of negative: 159399\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3317\n",
      "[LightGBM] [Info] Number of data points in the train set: 161870, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.015265 -> initscore=-4.166788\n",
      "[LightGBM] [Info] Start training from score -4.166788\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 2471, number of negative: 159399\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3317\n",
      "[LightGBM] [Info] Number of data points in the train set: 161870, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.015265 -> initscore=-4.166788\n",
      "[LightGBM] [Info] Start training from score -4.166788\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Validation ROC-AUC: 0.8553 | Time: 0.01 min\n",
      "LightGBM Validation ROC-AUC: 0.8553 | Time: 0.01 min\n",
      "LightGBM Learning Curve completed in 0.07 min\n",
      "LightGBM Learning Curve completed in 0.07 min\n",
      "CatBoost Validation ROC-AUC: 0.8684 | Time: 0.01 min\n",
      "CatBoost Validation ROC-AUC: 0.8684 | Time: 0.01 min\n",
      "CatBoost Learning Curve completed in 0.07 min\n",
      "\n",
      "Logging Final Performance on Test Set to MLflow:\n",
      "CatBoost Learning Curve completed in 0.07 min\n",
      "\n",
      "Logging Final Performance on Test Set to MLflow:\n",
      "{'XGBoost_test_roc_auc': 0.8679297318442137, 'XGBoost_test_accuracy': 0.9870452397279315, 'XGBoost_test_precision': 0.9133333333333333, 'XGBoost_test_recall': 0.16646415552855406, 'XGBoost_test_f1': 0.2816032887975334, 'XGBoost_test_log_loss': 0.05760196124114261}\n",
      "{'XGBoost_test_roc_auc': 0.8679297318442137, 'XGBoost_test_accuracy': 0.9870452397279315, 'XGBoost_test_precision': 0.9133333333333333, 'XGBoost_test_recall': 0.16646415552855406, 'XGBoost_test_f1': 0.2816032887975334, 'XGBoost_test_log_loss': 0.05760196124114261}\n",
      "{'LightGBM_test_roc_auc': 0.8605019515298695, 'LightGBM_test_accuracy': 0.9855811108845933, 'LightGBM_test_precision': 0.7848101265822784, 'LightGBM_test_recall': 0.07533414337788578, 'LightGBM_test_f1': 0.13747228381374724, 'LightGBM_test_log_loss': 0.06121900291843374}\n",
      "{'LightGBM_test_roc_auc': 0.8605019515298695, 'LightGBM_test_accuracy': 0.9855811108845933, 'LightGBM_test_precision': 0.7848101265822784, 'LightGBM_test_recall': 0.07533414337788578, 'LightGBM_test_f1': 0.13747228381374724, 'LightGBM_test_log_loss': 0.06121900291843374}\n",
      "{'CatBoost_test_roc_auc': 0.8699588756110836, 'CatBoost_test_accuracy': 0.98760123802287, 'CatBoost_test_precision': 0.9375, 'CatBoost_test_recall': 0.20048602673147023, 'CatBoost_test_f1': 0.3303303303303303, 'CatBoost_test_log_loss': 0.05570689128011065}\n",
      "{'CatBoost_test_roc_auc': 0.8699588756110836, 'CatBoost_test_accuracy': 0.98760123802287, 'CatBoost_test_precision': 0.9375, 'CatBoost_test_recall': 0.20048602673147023, 'CatBoost_test_f1': 0.3303303303303303, 'CatBoost_test_log_loss': 0.05570689128011065}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split, learning_curve, StratifiedShuffleSplit\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score,\n",
    "    f1_score, log_loss, roc_curve, precision_recall_curve\n",
    ")\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import time\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Set MLflow experiment to save logs in default './mlruns/' folder\n",
    "mlflow.set_tracking_uri(\"file:../mlruns\")\n",
    "mlflow.set_experiment(\"Vestiaire_Model_Comparison\")\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Filter dataset to the most important features\n",
    "important_features = [\n",
    "    'seller_price', 'seller_badge_encoded', 'should_be_gone', 'seller_pass_rate',\n",
    "    'price_to_earning_ratio', 'seller_products_sold', 'price_per_like', 'brand_id',\n",
    "    'product_type', 'product_material', 'product_like_count', 'seller_num_products_listed',\n",
    "    'seller_community_rank', 'seller_activity_ratio', 'product_color_encoded',\n",
    "    'seller_num_followers', 'margin_rate', 'available', 'seller_country', 'in_stock',\n",
    "    'product_season_encoded', 'usually_ships_within_encoded', 'product_condition_encoded',\n",
    "    'warehouse_name_encoded'\n",
    "]\n",
    "\n",
    "# Assuming your DataFrame is named 'df1'\n",
    "X = df1[important_features]\n",
    "y = df1['sold']\n",
    "\n",
    "# Use a sample of the dataset for faster experimentation (30% of data)\n",
    "X_sample, _, y_sample, _ = train_test_split(\n",
    "    X, y, train_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Split sample into train (60%), validation (20%), and test (20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_sample, y_sample, test_size=0.4, random_state=42, stratify=y_sample\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "def train_and_evaluate_with_mlflow(model, model_name, X_train, y_train, X_val, y_val, parent_run_id=None):\n",
    "    with mlflow.start_run(run_name=model_name, nested=True, parent_run_id=parent_run_id):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model on the training set\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_prob = model.predict_proba(X_val)[:, 1]\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Calculate metrics on validation set\n",
    "        roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        precision = precision_score(y_val, y_pred)\n",
    "        recall = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        logloss = log_loss(y_val, y_pred_prob)\n",
    "\n",
    "        elapsed_time = (time.time() - start_time) / 60\n",
    "        print(f\"{model_name} Validation ROC-AUC: {roc_auc:.4f} | Time: {elapsed_time:.2f} min\")\n",
    "\n",
    "        # Log parameters and validation metrics\n",
    "        mlflow.log_params(model.get_params())\n",
    "        mlflow.log_metrics({\n",
    "            \"roc_auc\": roc_auc,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1,\n",
    "            \"log_loss\": logloss\n",
    "        })\n",
    "\n",
    "        # Log curves as artifacts\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        fpr, tpr, _ = roc_curve(y_val, y_pred_prob)\n",
    "        plt.figure(); plt.plot(fpr, tpr, label=f\"ROC (AUC={roc_auc:.2f})\"); plt.plot([0,1],[0,1],'k--')\n",
    "        plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title(f\"{model_name} ROC (Validation)\"); plt.legend()\n",
    "        roc_path = os.path.join(temp_dir, f\"{model_name}_validation_roc.png\")\n",
    "        plt.savefig(roc_path); mlflow.log_artifact(roc_path); plt.close()\n",
    "\n",
    "        precision_vals, recall_vals, _ = precision_recall_curve(y_val, y_pred_prob)\n",
    "        plt.figure(); plt.plot(recall_vals, precision_vals, label=\"PR Curve\"); plt.xlabel('Recall'); plt.ylabel('Precision');\n",
    "        plt.title(f\"{model_name} PR (Validation)\"); plt.legend()\n",
    "        prc_path = os.path.join(temp_dir, f\"{model_name}_validation_prc.png\")\n",
    "        plt.savefig(prc_path); mlflow.log_artifact(prc_path); plt.close()\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "def plot_learning_curve_and_log(model, X_train, y_train, model_name):\n",
    "    start_time = time.time()\n",
    "    cv = StratifiedShuffleSplit(n_splits=2, test_size=0.3, random_state=42)\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        model, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1,\n",
    "        train_sizes=np.linspace(0.1, 0.5, 3)\n",
    "    )\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(train_sizes, train_mean, label=f\"{model_name} Train\")\n",
    "    plt.plot(train_sizes, test_mean, label=f\"{model_name} Validation\")\n",
    "    plt.title(f\"{model_name} Learning Curve\")\n",
    "    plt.xlabel(\"Training Size\"); plt.ylabel(\"ROC-AUC Score\"); plt.legend(); plt.grid()\n",
    "\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    plot_path = os.path.join(temp_dir, f\"{model_name}_learning_curve.png\")\n",
    "    plt.savefig(plot_path); mlflow.log_artifact(plot_path); plt.close()\n",
    "\n",
    "    elapsed_time = (time.time() - start_time) / 60\n",
    "    print(f\"{model_name} Learning Curve completed in {elapsed_time:.2f} min\")\n",
    "\n",
    "# Initialize models\n",
    "xgb_model = xgb.XGBClassifier(eval_metric='auc', random_state=42, n_estimators=30, max_depth=3, tree_method='hist', n_jobs=-1)\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42, n_estimators=30, max_depth=3, device='cpu')\n",
    "\n",
    "cat_model = cb.CatBoostClassifier(verbose=0, random_state=42, iterations=30, depth=3, task_type='CPU')\n",
    "\n",
    "# Parent run to group all child runs\n",
    "with mlflow.start_run(run_name=\"Model Comparison\") as parent_run:\n",
    "    parent_run_id = parent_run.info.run_id\n",
    "\n",
    "    # Validation experiments\n",
    "    xgb_model = train_and_evaluate_with_mlflow(xgb_model, \"XGBoost\", X_train, y_train, X_val, y_val, parent_run_id)\n",
    "    plot_learning_curve_and_log(xgb_model, X_train, y_train, \"XGBoost\")\n",
    "\n",
    "    lgb_model = train_and_evaluate_with_mlflow(lgb_model, \"LightGBM\", X_train, y_train, X_val, y_val, parent_run_id)\n",
    "    plot_learning_curve_and_log(lgb_model, X_train, y_train, \"LightGBM\")\n",
    "\n",
    "    cat_model = train_and_evaluate_with_mlflow(cat_model, \"CatBoost\", X_train, y_train, X_val, y_val, parent_run_id)\n",
    "    plot_learning_curve_and_log(cat_model, X_train, y_train, \"CatBoost\")\n",
    "\n",
    "    # Final evaluation on the held-out test set\n",
    "    with mlflow.start_run(run_name=\"Test_Evaluation\", nested=True, parent_run_id=parent_run_id):\n",
    "        print(\"\\nLogging Final Performance on Test Set to MLflow:\")\n",
    "        for model, model_name in [(xgb_model, \"XGBoost\"), (lgb_model, \"LightGBM\"), (cat_model, \"CatBoost\")]:\n",
    "            y_test_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            metrics = {\n",
    "                f\"{model_name}_test_roc_auc\": roc_auc_score(y_test, y_test_pred_prob),\n",
    "                f\"{model_name}_test_accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "                f\"{model_name}_test_precision\": precision_score(y_test, y_test_pred),\n",
    "                f\"{model_name}_test_recall\": recall_score(y_test, y_test_pred),\n",
    "                f\"{model_name}_test_f1\": f1_score(y_test, y_test_pred),\n",
    "                f\"{model_name}_test_log_loss\": log_loss(y_test, y_test_pred_prob)\n",
    "            }\n",
    "            print(metrics)\n",
    "            mlflow.log_metrics(metrics)\n",
    "\n",
    "            # Log test ROC and PR curves\n",
    "            temp_dir = tempfile.mkdtemp()\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_test_pred_prob)\n",
    "            plt.figure(); plt.plot(fpr, tpr, label=f\"ROC (AUC={metrics[f'{model_name}_test_roc_auc']:.2f})\"); plt.plot([0,1],[0,1],'k--')\n",
    "            plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title(f\"{model_name} ROC (Test)\"); plt.legend()\n",
    "            roc_path = os.path.join(temp_dir, f\"{model_name}_test_roc.png\")\n",
    "            plt.savefig(roc_path); mlflow.log_artifact(roc_path); plt.close()\n",
    "\n",
    "            precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_test_pred_prob)\n",
    "            plt.figure(); plt.plot(recall_vals, precision_vals, label=\"PR Curve\"); plt.xlabel('Recall'); plt.ylabel('Precision');\n",
    "            plt.title(f\"{model_name} PR (Test)\"); plt.legend()\n",
    "            prc_path = os.path.join(temp_dir, f\"{model_name}_test_prc.png\")\n",
    "            plt.savefig(prc_path); mlflow.log_artifact(prc_path); plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (real ml_workflow)",
   "language": "python",
   "name": "ml_workflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
